{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f902d2b3f03640409c70fc7def2ffac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_ceb97a2baea74bc89db875ceb74e8deb",
            "width": ""
          }
        },
        "ceb97a2baea74bc89db875ceb74e8deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bafe6be5254346b99462adf43565ad7c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_39facf44fec044749172e44821fa7eec",
            "msg_id": "",
            "outputs": []
          }
        },
        "39facf44fec044749172e44821fa7eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21a89fda5ed4cdda627b40137e6654e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_1185afde71f647a2a5fbbde89a2e8e6a",
            "width": ""
          }
        },
        "1185afde71f647a2a5fbbde89a2e8e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ec56a92d9747a2a4f32f03463da7b9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_082dbaa468ec4662a605e024efffd70b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "-----\n",
                  "X--X-\n",
                  "-----\n",
                  "-X-XX\n",
                  "----A\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "082dbaa468ec4662a605e024efffd70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f59e70a70eb4e548dff66d7df70d593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_a0eb05eedb464415999f296e8e4f5d30",
            "width": ""
          }
        },
        "a0eb05eedb464415999f296e8e4f5d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eeec93d10604c1a8aec78e1579d902f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a19a8211c6484f449994ecc9eebd3114",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "-----X----\n",
                  "XXXX-X-X-X\n",
                  "-----X-X--\n",
                  "-XXX-X-X-X\n",
                  "---X---X--\n",
                  "-X----X---\n",
                  "-XXXXXXX-X\n",
                  "---X-----A\n",
                  "-X----XXX-\n",
                  "-X--X-----\n",
                  "\n",
                  "Action: Right (3)\n"
                ]
              }
            ]
          }
        },
        "a19a8211c6484f449994ecc9eebd3114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Value Iteration**\n",
        "\n",
        "*Created by Pulkit Rustagi, Jeff Jewett, Will Solow, 2024\n",
        "Oregon State AIGSA Reading Group*\n",
        "\n",
        "This Google Colab notebook is made to help students understand and visualize process of value iteration, to solve a Markov Decision Process (MDP) using the example of a grid maze."
      ],
      "metadata": {
        "id": "s2zZnViBNh0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run this block to install and import dependencies**"
      ],
      "metadata": {
        "id": "2POwBcxSpvNq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0oLt_6ymJRW",
        "outputId": "d5a8705b-713f-4008-e556-f784bbb45451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Install requisite packages\"\"\"\n",
        "!pip install gymnasium[classic-control]\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "\"\"\"Import packages\"\"\"\n",
        "import io\n",
        "import time\n",
        "import gymnasium as gym\n",
        "import ipywidgets\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utility functions**"
      ],
      "metadata": {
        "id": "HqSyESIauekG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Utility functions\"\"\"\n",
        "def image_to_bytes(img):\n",
        "  if isinstance(img, np.ndarray):\n",
        "    img = Image.fromarray(img, 'RGB')\n",
        "\n",
        "  # Convert the PIL image to bytes\n",
        "  with io.BytesIO() as output:\n",
        "    img.save(output, format=\"PNG\")\n",
        "    image_data = output.getvalue()\n",
        "  return image_data\n",
        "\n",
        "def matrix_to_heatmap_image(matrix, output_size=(512, 512),display_val=False):\n",
        "  norm_factor = max(np.abs(np.nanmax(matrix)), np.abs(np.nanmin(matrix)))\n",
        "  if norm_factor != 0:\n",
        "    matrix = matrix / norm_factor\n",
        "  cmap = plt.get_cmap('coolwarm')\n",
        "  cmap.set_bad(color='black')\n",
        "  norm = plt.Normalize(vmin=-1, vmax=1)\n",
        "  rgb_array = cmap(norm(matrix))[:, :, :3]\n",
        "  rgb_image = Image.fromarray((rgb_array * 255).astype(np.uint8))\n",
        "\n",
        "  # Resize the image to the specified output size\n",
        "  resized_image = rgb_image.resize(output_size, Image.NEAREST)\n",
        "\n",
        "  if display_val:\n",
        "    # Draw text on the heatmap\n",
        "    draw = ImageDraw.Draw(resized_image)\n",
        "    num_rows, num_cols = matrix.shape\n",
        "    cell_width = output_size[0] / num_cols\n",
        "    cell_height = output_size[1] / num_rows\n",
        "\n",
        "    # Overlay text\n",
        "    for i in range(num_rows):\n",
        "      for j in range(num_cols):\n",
        "        value = matrix[i, j]\n",
        "        # Calculate position for the text\n",
        "        text_position = (j * cell_width + cell_width / 2, i * cell_height + cell_height / 2)\n",
        "        text_color = 'black' if value > 0 else 'white'  # Choose text color based on value\n",
        "\n",
        "        # Draw the text centered in the cell\n",
        "        draw.text(text_position, f\"{value:.1f}\", fill=text_color, anchor=\"mm\", font=20)\n",
        "\n",
        "  return np.array(resized_image)"
      ],
      "metadata": {
        "id": "9cIxGGIYubU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MDP Class**"
      ],
      "metadata": {
        "id": "5I-i6NQPqRc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeMDP():\n",
        "\n",
        "  MOVES: dict[int,tuple] = {\n",
        "         0: np.array([-1, 0]), #UP\n",
        "         1: np.array([1, 0]),  #DOWN\n",
        "         2: np.array([0, -1]), #LEFT\n",
        "         3: np.array([0, 1])   #RIGHT\n",
        "         }\n",
        "  UP: int = 0\n",
        "  DOWN: int = 1\n",
        "  LEFT: int = 2\n",
        "  RIGHT: int = 3\n",
        "\n",
        "  def __init__(self, maze, H=100, gamma=.95):\n",
        "    \"\"\"Initialize the MDP\"\"\"\n",
        "    self.maze = np.array(maze)\n",
        "    assert len(self.maze.shape) == 2, \"The maze must be a 2-dimensional array\"\n",
        "\n",
        "    self.obstacles = [tuple(loc) for loc in np.argwhere(self.maze == 1)]\n",
        "    def get_state_index_from_maze(value):\n",
        "      locations = [tuple(loc) for loc in np.argwhere(self.maze == value)]\n",
        "      assert len(locations) == 1, f\"There should be exactly one {value} in the maze\"\n",
        "      row, col = locations[0]\n",
        "      return self.row_col_to_state(row, col)\n",
        "    self.init_state = get_state_index_from_maze(2)\n",
        "    self.goal_state = get_state_index_from_maze(3)\n",
        "\n",
        "    \"\"\"Create the MDP functions\"\"\"\n",
        "    self.S = set(range(self.maze.shape[0] * self.maze.shape[1]))\n",
        "    self.A = set(range(len(self.MOVES)))\n",
        "    self.R = self.build_rewards()\n",
        "    self.P = self.build_transitions()\n",
        "\n",
        "    self.H = H\n",
        "    self.gamma = gamma\n",
        "\n",
        "\n",
        "  def build_rewards(self):\n",
        "    \"\"\"Build reward function\"\"\"\n",
        "    # make every state and action and next state give -1 reward, to penalize long paths\n",
        "    rewards = np.full((len(self.S), len(self.A), len(self.S)), -1, dtype=float)\n",
        "    # all actions in the goal state give zero reward\n",
        "    # this is a requirement for all terminating states\n",
        "    rewards[self.goal_state, :, :] = 0\n",
        "\n",
        "    return rewards\n",
        "  def build_transitions(self):\n",
        "    \"\"\"Build transitoins function\"\"\"\n",
        "    transitions = np.zeros((len(self.S), len(self.A), len(self.S)))\n",
        "\n",
        "    # Go through all states and all actions\n",
        "    for s in self.S:\n",
        "      for a in self.A:\n",
        "        # By default, the next state is the current state\n",
        "        s_p = s\n",
        "\n",
        "        # Convert state to maze index\n",
        "        row_col = np.array(self.state_to_row_col(s))\n",
        "\n",
        "        # Get new potential state\n",
        "        row_col_new = row_col + self.MOVES[a]\n",
        "\n",
        "        # Check that new state is valid\n",
        "        is_in_bounds = 0 <= row_col_new[0] < self.maze.shape[0] and 0 <= row_col_new[1] < self.maze.shape[1]\n",
        "        is_free_space = tuple(row_col_new) not in self.obstacles\n",
        "\n",
        "        # Compute the new s' if the transition is valid\n",
        "        if is_in_bounds and is_free_space:\n",
        "          s_p = self.row_col_to_state(*row_col_new)\n",
        "\n",
        "        # Assign transition probability to 1\n",
        "        transitions[s,a,s_p] = 1\n",
        "\n",
        "    return transitions\n",
        "\n",
        "  def state_to_row_col(self, state):\n",
        "    \"\"\"A utility function to get the row and col from a state index\"\"\"\n",
        "    return state // self.maze.shape[1], state % self.maze.shape[1]\n",
        "\n",
        "  def row_col_to_state(self, row, col):\n",
        "    \"\"\"A utility function to get the state index from row and col\"\"\"\n",
        "    return row * self.maze.shape[1] + col"
      ],
      "metadata": {
        "id": "i_ppktdsmU9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simplified Implementation**"
      ],
      "metadata": {
        "id": "9mTGecTcQO0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeMDPNew():\n",
        "\n",
        "  MOVES: dict[int,tuple] = {\n",
        "         0: np.array([-1, 0]), #UP\n",
        "         1: np.array([1, 0]),  #DOWN\n",
        "         2: np.array([0, -1]), #LEFT\n",
        "         3: np.array([0, 1])   #RIGHT\n",
        "         }\n",
        "  UP: int = 0\n",
        "  DOWN: int = 1\n",
        "  LEFT: int = 2\n",
        "  RIGHT: int = 3\n",
        "\n",
        "  def __init__(self, maze, H=100, gamma=1):\n",
        "    \"\"\"Initialize the MDP\"\"\"\n",
        "    self.maze = np.array(maze)\n",
        "    assert len(self.maze.shape) == 2, \"The maze must be a 2-dimensional array\"\n",
        "    self.obstacles = [tuple(loc) for loc in np.argwhere(self.maze == 1)]\n",
        "\n",
        "    def get_state_index_from_maze(value):\n",
        "      locations = [tuple(loc) for loc in np.argwhere(self.maze == value)]\n",
        "      assert len(locations) == 1, f\"There should be exactly one {value} in the maze\"\n",
        "      row, col = locations[0]\n",
        "      return self.row_col_to_state(row, col)\n",
        "\n",
        "    self.init_state = get_state_index_from_maze(2)\n",
        "    self.goal_state = get_state_index_from_maze(3)\n",
        "\n",
        "    \"\"\"Create the MDP functions\"\"\"\n",
        "    self.S = set(range(self.maze.shape[0] * self.maze.shape[1]))\n",
        "    self.A = set(range(len(self.MOVES)))\n",
        "    self.R = self.get_reward_function()\n",
        "    self.P = self.get_transition_function()\n",
        "\n",
        "    self.H = H\n",
        "    self.gamma = gamma\n",
        "\n",
        "\n",
        "  def get_reward_function(self):\n",
        "    \"\"\"Build reward function\"\"\"\n",
        "    # make every state -1 reward, to penalize long paths\n",
        "    rewards = np.full((len(self.S)), -1, dtype=float)\n",
        "    # however goal state reward is 0, so you are not penalized to reach the goal\n",
        "    rewards[self.goal_state] = 0\n",
        "    return rewards\n",
        "\n",
        "  def get_transition_function(self):\n",
        "    \"\"\"Build transitoins function\"\"\"\n",
        "    transitions = np.zeros((len(self.S), len(self.A), len(self.S)))\n",
        "\n",
        "    # Go through all states and all actions\n",
        "    for s in self.S:\n",
        "      for a in self.A:\n",
        "        # By default, the next state is the current state\n",
        "        s_next = s\n",
        "\n",
        "        # Convert state to maze index\n",
        "        state_as_row_col = np.array(self.state_to_row_col(s))\n",
        "\n",
        "        # Get new potential state\n",
        "        next_state_as_row_col = state_as_row_col + self.MOVES[a]\n",
        "\n",
        "        # Check that new state is valid\n",
        "        next_state_is_in_bounds = (0 <= next_state_as_row_col[0] < self.maze.shape[0]) and (0 <= next_state_as_row_col[1] < self.maze.shape[1])\n",
        "        next_state_is_free_space = tuple(next_state_as_row_col) not in self.obstacles\n",
        "\n",
        "        # Compute the new s_next if the transition is valid\n",
        "        if next_state_is_in_bounds and next_state_is_free_space:\n",
        "          s_next = self.row_col_to_state(*next_state_as_row_col)\n",
        "\n",
        "        # Assign transition probability to 1\n",
        "        transitions[s,a,s_next] = 1\n",
        "\n",
        "    return transitions\n",
        "\n",
        "  def state_to_row_col(self, state):\n",
        "    \"\"\"A utility function to get the row and col from a state index\"\"\"\n",
        "    return state // self.maze.shape[1], state % self.maze.shape[1]\n",
        "\n",
        "  def row_col_to_state(self, row, col):\n",
        "    \"\"\"A utility function to get the state index from row and col\"\"\"\n",
        "    return row * self.maze.shape[1] + col"
      ],
      "metadata": {
        "id": "UcuD72qLQNYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gym Environment**\n",
        "\n",
        "\n",
        "```\n",
        "Class functions to take note of:\n",
        "reset(): resets to starting conditions\n",
        "step(action): takes 'action' at current state to agent\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_K9MLDr5qXSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define the Maze Gym Environment\"\"\"\n",
        "class MazeEnv(gym.Env):\n",
        "\n",
        "  def __init__(self, mdp, render_mode = \"ansi\"):\n",
        "    \"\"\"Initialize the maze environment setting all variables and parsing the map\"\"\"\n",
        "    self.mdp = mdp\n",
        "\n",
        "    self.agent_curr_state = self.mdp.init_state\n",
        "    self.steps_taken = 0\n",
        "\n",
        "    # Set action space and observation space\n",
        "    self.action_space = gym.spaces.Discrete(len(self.mdp.A))\n",
        "    self.observation_space = gym.spaces.Discrete(len(self.mdp.S))  # you observe what state you are in\n",
        "\n",
        "    # Rendering\n",
        "    self.render_mode = render_mode\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Reset the environment to its initial state\"\"\"\n",
        "    self.agent_curr_state = self.mdp.init_state\n",
        "    self.steps_taken = 0\n",
        "\n",
        "    initial_obs = self.agent_curr_state\n",
        "    initial_info = {}\n",
        "\n",
        "    return initial_obs, initial_info\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Take an action in the environment\"\"\"\n",
        "\n",
        "    assert 0 <= action < 4, \"Action should be one of [0,1,2,3]\"\n",
        "    s = self.agent_curr_state\n",
        "    s_next = self.agent_curr_state\n",
        "    # Sample next state weighted by transition probabilities\n",
        "    s_next = np.random.choice(list(self.mdp.S), 1, p=self.mdp.P[s, action,:])[0]\n",
        "    self.agent_curr_state = s_next\n",
        "\n",
        "    # Get reward according the state you are in\n",
        "    # reminder of Bellman equation:  V(s) = R(s) + sum T(s,a,s_next).V(s_next)\n",
        "    reward = self.mdp.R[s]\n",
        "\n",
        "    # Make outputs for gym environment\n",
        "    next_obs = s_next\n",
        "\n",
        "    self.steps_taken += 1\n",
        "    has_reached_goal = (s_next == self.mdp.goal_state)\n",
        "    has_reached_time_limit = (self.steps_taken >= self.mdp.H)\n",
        "    terminated = (has_reached_goal or has_reached_time_limit)\n",
        "\n",
        "    # truncated indicates that the episode was ended due to some external condition\n",
        "    truncated = False\n",
        "    # info can contain auxillary information for logging and debugging\n",
        "    info = {}\n",
        "\n",
        "    return next_obs, reward, terminated, truncated, info\n",
        "\n",
        "  def render(self):\n",
        "    \"\"\" Render the environment \"\"\"\n",
        "\n",
        "    if self.render_mode == \"ansi\":\n",
        "      # ansi is text mode\n",
        "      return render_text(self.agent_curr_state, self.mdp.maze)\n",
        "    else:\n",
        "      raise ValueError(f\"Unsupported rendering mode {self.render_mode}\")\n",
        "\n",
        "def render_text(agent_state, maze):\n",
        "  \"\"\"Get a text form of the maze\"\"\"\n",
        "\n",
        "  # These are the characters that will render in your maze.\n",
        "  # 0 = \"-\" is empty space\n",
        "  # 1 = \"X\" is a wall\n",
        "  # 2 = \"-\" is the agent starting location. However, it can be rendered as empty space\n",
        "  # 3 = \"G\" is the goal location\n",
        "  # 4 = \"T\" is a teleporter (you will implement this)\n",
        "  # extend this list if you add more features\n",
        "  character_map = [\"-\", \"X\", \"-\", \"G\", \"T\"]\n",
        "  ncols, nrows = maze.shape\n",
        "\n",
        "  string=f\"\"\n",
        "  for i in range(ncols):\n",
        "    for j in range(nrows):\n",
        "      s = (i * ncols + j)\n",
        "      if s == agent_state:\n",
        "        # The agent is displayed as \"A\"\n",
        "        string += \"A\"\n",
        "      else:\n",
        "        string += character_map[maze[i, j]]\n",
        "    string += \"\\n\"\n",
        "\n",
        "  return string\n"
      ],
      "metadata": {
        "id": "BfiBhMYMms9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Value Iteration Agent Class**\n",
        "Bellman Backup\n",
        "\n",
        "  ![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "gTinRfRsqwL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ValueIterationAgent():\n",
        "  \"\"\"Agent class for solving tabular MDPs\"\"\"\n",
        "\n",
        "  def __init__(self, env):\n",
        "    \"\"\"Initialize the agent. env should have a tabular mdp\"\"\"\n",
        "\n",
        "    assert hasattr(env, 'mdp'), \"Gymansium Environment does not have associated MDP\"\n",
        "\n",
        "    self.env = env\n",
        "    self.mdp = env.mdp\n",
        "    self.policy = None\n",
        "    self.v = None\n",
        "    self.v_iterations = []\n",
        "\n",
        "  def value_iteration(self, epsilon=.000001):\n",
        "    \"\"\"Perform value improvement\"\"\"\n",
        "    mdp = self.mdp\n",
        "    S = mdp.S\n",
        "    A = mdp.A\n",
        "    # Randomly initialize v\n",
        "    # Easiest initialization is all zeros\n",
        "    v = np.zeros(len(S))\n",
        "\n",
        "    # Loop until the horizon is reached\n",
        "    for i in range(mdp.H):\n",
        "\n",
        "      old_v = v.copy()\n",
        "\n",
        "      v = np.max(np.sum(mdp.P * (mdp.R + v[np.newaxis, np.newaxis, :]), axis=-1), axis=-1)\n",
        "\n",
        "      # # Iterate over each state\n",
        "      # for s in S:\n",
        "      #   # Iterate over each action\n",
        "      #   action_values = np.zeros(len(A))\n",
        "      #   for a in A:  # Store Q-values for each action\n",
        "      #     q_value = 0\n",
        "      #     # Iterate over next states to calculate expected value\n",
        "      #     for next_s in S:\n",
        "      #       transition_prob = mdp.P[s, a, next_s]  # Probability of transitioning to next_s\n",
        "      #       reward = mdp.R[s, a, next_s]  # Reward for taking action a in state s, ending in next_s\n",
        "      #       q_value += transition_prob * (reward + old_v[next_s])  # Bellman equation with reward\n",
        "\n",
        "      #     action_values[a] = q_value  # Store Q-value for action a\n",
        "\n",
        "      #   # Update the value function for state s\n",
        "      #   v[s] = np.max(action_values)  # Take the max over actions\n",
        "      #   self.v_iterations.append(v)\n",
        "\n",
        "      # Set goal state value to 0\n",
        "      v[mdp.goal_state] = 0\n",
        "      self.v_iterations.append(v)\n",
        "      # Exit if threshold is reached\n",
        "      if i > 30 and np.max(np.abs(old_v-v)) < epsilon:\n",
        "        break\n",
        "\n",
        "    # Determine the best actions with bellman backups\n",
        "    action_reward = np.sum(mdp.P * (mdp.R + mdp.gamma * v[np.newaxis, np.newaxis, :]), axis=-1)\n",
        "\n",
        "    # Compute the optimal policy\n",
        "    best_actions = (action_reward - np.max(action_reward, axis=1)[:,np.newaxis]) == 0\n",
        "    policy = best_actions * (1 / np.sum( best_actions, axis=1)[:,np.newaxis])\n",
        "\n",
        "    self.policy = policy\n",
        "    self.v = v\n",
        "\n",
        "    return policy, v\n",
        "\n",
        "  def get_action(self, state):\n",
        "    \"\"\"Get the action given by the policy\"\"\"\n",
        "\n",
        "    # If policy is none, return a random action\n",
        "    if self.policy is None:\n",
        "      print(\"Warning: Value iteration policy has not been computed yet\")\n",
        "      return self.env.action_space.sample()\n",
        "\n",
        "    # Get the action given by the policy\n",
        "    action = np.random.choice(list(self.mdp.A), 1, p=self.policy[state,:])[0]\n",
        "\n",
        "    return action\n",
        "\n",
        "  def get_value(self, state):\n",
        "    \"\"\"Get the value of a given state\"\"\"\n",
        "\n",
        "    return self.v[state]\n",
        "\n",
        "  def get_value_heatmap(self, agent_state, output_shape=(256,256)):\n",
        "    \"\"\"Gets a matrix of all the state values\"\"\"\n",
        "    value_matrix = self.v.reshape((self.mdp.maze.shape))\n",
        "    # arr = np.nan_to_num(arr, nan=10000)\n",
        "    for loc in self.mdp.obstacles:\n",
        "      value_matrix[loc] = np.nan\n",
        "    image = matrix_to_heatmap_image(value_matrix, output_shape)\n",
        "    # draw agent\n",
        "    agent_frac_x = (agent_state // self.mdp.maze.shape[1] + 0.5) / self.mdp.maze.shape[0]\n",
        "    agent_frac_y = (agent_state % self.mdp.maze.shape[1] + 0.5) / self.mdp.maze.shape[1]\n",
        "    x_half_width = output_shape[0] / self.mdp.maze.shape[0] * 0.25\n",
        "    y_half_width = output_shape[1] / self.mdp.maze.shape[1] * 0.25\n",
        "    min_x = int(output_shape[0] * agent_frac_x - x_half_width)\n",
        "    max_x = int(output_shape[0] * agent_frac_x + x_half_width)\n",
        "    min_y = int(output_shape[1] * agent_frac_y - y_half_width)\n",
        "    max_y = int(output_shape[1] * agent_frac_y + y_half_width)\n",
        "    image[min_x:max_x, min_y:max_y,:] = 255\n",
        "    return image\n",
        "\n",
        "\n",
        "  def get_value_iteration_heatmap(self, v_iteration, output_shape=(256,256)):\n",
        "    \"\"\"Gets a matrix of all the state values\"\"\"\n",
        "    value_matrix = v_iteration.reshape((self.mdp.maze.shape))\n",
        "    # arr = np.nan_to_num(arr, nan=10000)\n",
        "    for loc in self.mdp.obstacles:\n",
        "      value_matrix[loc] = np.nan\n",
        "    image = matrix_to_heatmap_image(value_matrix, output_shape)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "EaLT-WfDmtO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize values updates from value iteration**"
      ],
      "metadata": {
        "id": "AljeO30wvkig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS_PER_SECOND = 2\n",
        "output = ipywidgets.Output()\n",
        "image_widget = ipywidgets.Image()\n",
        "display(image_widget)\n",
        "display(output)\n",
        "\n",
        "# Create our MDP to specify the maze\n",
        "\n",
        "# Create the maze MDP.\n",
        "#       0 is free space,\n",
        "#       1 is walls,\n",
        "#       2 is the starting location,\n",
        "#       3 is the goal location\n",
        "mdp = MazeMDP([[2,0,0,0,0],\n",
        "               [1,0,0,1,0],\n",
        "               [0,0,0,0,0],\n",
        "               [0,1,0,1,1],\n",
        "               [0,0,0,0,3]])\n",
        "\n",
        "# Create the maze gym environment\n",
        "maze_env = MazeEnv(mdp)\n",
        "\n",
        "# Create and call a value iteration agent\n",
        "agent = ValueIterationAgent(maze_env)\n",
        "V, policy = agent.value_iteration()\n",
        "\n",
        "terminated = truncated = done = False\n",
        "obs, info = maze_env.reset()\n",
        "num_steps = 0\n",
        "\n",
        "# Assuming agent.v_iterations is a list of value arrays for each iteration\n",
        "for i, v in enumerate(agent.v_iterations):\n",
        "  # Reshape the value array to match the maze dimensions\n",
        "  value_matrix = v.reshape(mdp.maze.shape)\n",
        "  # print(value_matrix)\n",
        "  value_heatmap = agent.get_value_iteration_heatmap(value_matrix)\n",
        "  image_widget.value = image_to_bytes(value_heatmap)\n",
        "\n",
        "  time.sleep(3/STEPS_PER_SECOND)\n",
        "  num_steps += 1\n",
        "\n",
        "print(f\"Finished in {num_steps} steps\")\n",
        "# print(agent.v_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "f902d2b3f03640409c70fc7def2ffac5",
            "ceb97a2baea74bc89db875ceb74e8deb",
            "bafe6be5254346b99462adf43565ad7c",
            "39facf44fec044749172e44821fa7eec"
          ]
        },
        "id": "_Cy9w4AEwQwb",
        "outputId": "4e929302-cceb-4fbe-e240-562452e39e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f902d2b3f03640409c70fc7def2ffac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bafe6be5254346b99462adf43565ad7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 832 steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize agent using value iteration**"
      ],
      "metadata": {
        "id": "oQkJpexIv8qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS_PER_SECOND = 2\n",
        "output = ipywidgets.Output()\n",
        "image_widget = ipywidgets.Image()\n",
        "display(image_widget)\n",
        "display(output)\n",
        "\n",
        "# Create our MDP to specify the maze\n",
        "\n",
        "# Create the maze MDP.\n",
        "#       0 is free space,\n",
        "#       1 is walls,\n",
        "#       2 is the starting location,\n",
        "#       3 is the goal location\n",
        "mdp = MazeMDP([[2,0,0,0,0],\n",
        "               [1,0,0,1,0],\n",
        "               [0,0,0,0,0],\n",
        "               [0,1,0,1,1],\n",
        "               [0,0,0,0,3]])\n",
        "\n",
        "# Create the maze gym environment\n",
        "maze_env = MazeEnv(mdp)\n",
        "\n",
        "# Create and call a value iteration agent\n",
        "agent = ValueIterationAgent(maze_env)\n",
        "agent.value_iteration()\n",
        "\n",
        "terminated = truncated = done = False\n",
        "state, info = maze_env.reset()\n",
        "num_steps = 0\n",
        "\n",
        "# Run the maze environment until the episode terminates\n",
        "while not done and num_steps < 100:\n",
        "  # Get best action from the agent policy\n",
        "  action = agent.get_action(state)\n",
        "\n",
        "  next_state, reward, terminated, truncated, info = maze_env.step(action)\n",
        "  done = terminated or truncated\n",
        "  state = next_state\n",
        "\n",
        "  # Render\n",
        "  with output:\n",
        "    clear_output(wait=True)\n",
        "    print(maze_env.render())\n",
        "  value_heatmap = agent.get_value_heatmap(state)\n",
        "  image_widget.value = image_to_bytes(value_heatmap)\n",
        "\n",
        "  time.sleep(1/STEPS_PER_SECOND)\n",
        "  num_steps += 1\n",
        "\n",
        "print(f\"Finished in {num_steps} steps\")\n",
        "# print(agent.v_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "e21a89fda5ed4cdda627b40137e6654e",
            "1185afde71f647a2a5fbbde89a2e8e6a",
            "83ec56a92d9747a2a4f32f03463da7b9",
            "082dbaa468ec4662a605e024efffd70b"
          ]
        },
        "id": "2CqbEhXJmtRX",
        "outputId": "d0f3bfd9-f46e-49bc-d553-5c618be05844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e21a89fda5ed4cdda627b40137e6654e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83ec56a92d9747a2a4f32f03463da7b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 8 steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimal agent in a larger grid**"
      ],
      "metadata": {
        "id": "N987_LUQpX0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS_PER_SECOND = 2\n",
        "output = ipywidgets.Output()\n",
        "image_widget = ipywidgets.Image()\n",
        "display(image_widget)\n",
        "display(output)\n",
        "\n",
        "# Create the alternate reward MDP. Select a maze.\n",
        "gamma = 0.95\n",
        "maze = [[2,0,0,0,0,1,0,0,0,0],\n",
        "        [1,1,1,1,0,1,0,1,0,1],\n",
        "        [0,0,0,0,0,1,0,1,0,0],\n",
        "        [0,1,1,1,0,1,0,1,0,1],\n",
        "        [0,0,0,1,0,0,0,1,0,0],\n",
        "        [0,1,0,0,0,0,1,0,0,0],\n",
        "        [0,1,1,1,1,1,1,1,0,1],\n",
        "        [0,0,0,1,0,0,0,0,0,3],\n",
        "        [0,1,0,0,0,0,1,1,1,0],\n",
        "        [0,1,0,0,1,0,0,0,0,0],]\n",
        "\n",
        "mdp = MazeMDP(maze, gamma=0.95)\n",
        "\n",
        "# Create the maze gym environment\n",
        "maze_env = MazeEnv(mdp)\n",
        "\n",
        "# Create and call a value iteration agent\n",
        "agent = ValueIterationAgent(maze_env)\n",
        "agent.value_iteration()\n",
        "\n",
        "terminated = truncated = done = False\n",
        "obs, info = maze_env.reset()\n",
        "num_steps = 0\n",
        "total_reward = 0\n",
        "\n",
        "# Run the maze environment until the episode terminates\n",
        "while not done and num_steps < 40:\n",
        "  # Get best action from the agent policy\n",
        "  action = agent.get_action(obs)\n",
        "\n",
        "  next_obs, reward, terminated, truncated, info = maze_env.step(action)\n",
        "  done = terminated or truncated\n",
        "  obs = next_obs\n",
        "  total_reward += reward\n",
        "\n",
        "  # Render\n",
        "  with output:\n",
        "    clear_output(wait=True)\n",
        "    print(maze_env.render())\n",
        "    print(f'Action: {[\"Up\",\"Down\",\"Left\",\"Right\"][action]} ({action})')\n",
        "  value_heatmap = agent.get_value_heatmap(obs)\n",
        "  image_widget.value = image_to_bytes(value_heatmap)\n",
        "\n",
        "  time.sleep(1/STEPS_PER_SECOND)\n",
        "  num_steps += 1\n",
        "\n",
        "print(f\"Finished in {num_steps} steps with {total_reward} reward\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f59e70a70eb4e548dff66d7df70d593",
            "a0eb05eedb464415999f296e8e4f5d30",
            "4eeec93d10604c1a8aec78e1579d902f",
            "a19a8211c6484f449994ecc9eebd3114"
          ]
        },
        "id": "ua-aisEqmtTr",
        "outputId": "e1d746c8-75c7-446a-85a5-b2c1d50fc56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f59e70a70eb4e548dff66d7df70d593"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eeec93d10604c1a8aec78e1579d902f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 24 steps with [[-24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24.]\n",
            " [-24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24.]\n",
            " [-24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24.]\n",
            " [-24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24. -24.\n",
            "  -24. -24.]] reward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSUaX411mtWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OO12OvGhmtYz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}